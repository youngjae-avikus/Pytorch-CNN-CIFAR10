{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ResNet\n",
    "\n",
    "- ResNet은 CNN 중에서 가장 많이 쓰이는 모델\n",
    "- VGG는 19층 이상으로 쌓을 수 없다. 다만 ResNet은 Skip Connection 기술을 이용해서 기울시 소실을 방지함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ResNet 기본 블록 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.c1 = nn.Conv2d(in_channels, out_channels, \n",
    "                            kernel_size=kernel_size, padding=1)\n",
    "        self.c2 = nn.Conv2d(out_channels, out_channels, \n",
    "                            kernel_size=kernel_size, padding=1)\n",
    "        self.downsample = nn.Conv2d(in_channels, out_channels, \n",
    "                                    kernel_size=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_ = x\n",
    "        \n",
    "        x = self.c1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        # 합성곱의 결과와 입력의 채널 수를 맞춤\n",
    "        x_ = self.downsample(x_)\n",
    "        \n",
    "        x += x_\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ResNet 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.b1 = BasicBlock(in_channels=3, out_channels=64)\n",
    "        self.b2 = BasicBlock(in_channels=64, out_channels=128)\n",
    "        self.b3 = BasicBlock(in_channels=128, out_channels=256)\n",
    "        \n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "                \n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 전처리 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torchvision.transforms import RandomCrop, RandomHorizontalFlip\n",
    "from torchvision.transforms import Normalize\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from torch.optim.adam import Adam\n",
    "\n",
    "transforms = Compose([\n",
    "    RandomCrop((32,32), padding=4),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data = CIFAR10(root='./', train=True, download=True, transform=transforms)\n",
    "test_data = CIFAR10(root='./', train=False, download=True, transform=transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=training_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (b1): BasicBlock(\n",
       "    (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (b2): BasicBlock(\n",
       "    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (b3): BasicBlock(\n",
       "    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc1): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ResNet(num_classes=10)\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습 루프 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss:0.9484152793884277: 100%|██████████| 782/782 [00:12<00:00, 63.69it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6916\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2 loss:0.5299801826477051: 100%|██████████| 782/782 [00:12<00:00, 63.25it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 120.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7324\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3 loss:0.8240244388580322: 100%|██████████| 782/782 [00:12<00:00, 63.30it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 120.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7697\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4 loss:0.3468015491962433: 100%|██████████| 782/782 [00:12<00:00, 63.28it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 121.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7926\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5 loss:0.48342499136924744: 100%|██████████| 782/782 [00:12<00:00, 63.13it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7943\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6 loss:0.27809107303619385: 100%|██████████| 782/782 [00:12<00:00, 63.14it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8199\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7 loss:0.4314178228378296: 100%|██████████| 782/782 [00:12<00:00, 63.39it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 121.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8207\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8 loss:0.18510626256465912: 100%|██████████| 782/782 [00:12<00:00, 63.19it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 120.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8349\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9 loss:0.3514291048049927: 100%|██████████| 782/782 [00:12<00:00, 63.42it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 123.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8448\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 10 loss:0.40302810072898865: 100%|██████████| 782/782 [00:12<00:00, 63.13it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 11 loss:0.3962790369987488: 100%|██████████| 782/782 [00:12<00:00, 63.48it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 121.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8467\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 12 loss:0.40217676758766174: 100%|██████████| 782/782 [00:12<00:00, 63.57it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8471\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 13 loss:0.35029876232147217: 100%|██████████| 782/782 [00:12<00:00, 63.49it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8512\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 14 loss:0.10817859321832657: 100%|██████████| 782/782 [00:12<00:00, 63.36it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8548\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 15 loss:0.5675683617591858: 100%|██████████| 782/782 [00:12<00:00, 63.28it/s]  \n",
      "100%|██████████| 157/157 [00:01<00:00, 121.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8637\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 16 loss:0.22054070234298706: 100%|██████████| 782/782 [00:12<00:00, 63.75it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 122.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8642\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 17 loss:0.6785425543785095: 100%|██████████| 782/782 [00:12<00:00, 63.44it/s]  \n",
      "100%|██████████| 157/157 [00:01<00:00, 120.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 18 loss:0.008485511876642704: 100%|██████████| 782/782 [00:12<00:00, 63.37it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8656\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 19 loss:0.16727641224861145: 100%|██████████| 782/782 [00:12<00:00, 63.65it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 121.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8714\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 20 loss:0.22029522061347961: 100%|██████████| 782/782 [00:12<00:00, 63.50it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 122.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8738\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 21 loss:0.14009307324886322: 100%|██████████| 782/782 [00:12<00:00, 63.44it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 122.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 22 loss:0.15267018973827362: 100%|██████████| 782/782 [00:12<00:00, 63.08it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 121.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 23 loss:0.16239304840564728: 100%|██████████| 782/782 [00:12<00:00, 63.55it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 121.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 24 loss:0.026315953582525253: 100%|██████████| 782/782 [00:12<00:00, 63.29it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8774\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 25 loss:0.0424097515642643: 100%|██████████| 782/782 [00:12<00:00, 62.61it/s]  \n",
      "100%|██████████| 157/157 [00:01<00:00, 121.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 26 loss:0.07891726493835449: 100%|██████████| 782/782 [00:12<00:00, 63.21it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 121.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 27 loss:0.01508516538888216: 100%|██████████| 782/782 [00:12<00:00, 63.17it/s] \n",
      "100%|██████████| 157/157 [00:01<00:00, 121.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8776\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 28 loss:0.1348452866077423: 100%|██████████| 782/782 [00:12<00:00, 63.19it/s]  \n",
      "100%|██████████| 157/157 [00:01<00:00, 122.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 29 loss:0.041985027492046356: 100%|██████████| 782/782 [00:12<00:00, 63.17it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 121.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8823\n",
      "Save Pth!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 30 loss:0.038432877510786057: 100%|██████████| 782/782 [00:12<00:00, 63.45it/s]\n",
      "100%|██████████| 157/157 [00:01<00:00, 122.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "max_acc = 0\n",
    "\n",
    "for epoch in range(30):\n",
    "    iterator = tqdm.tqdm(train_loader)\n",
    "    \n",
    "    for data, label in iterator:\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        preds = model(data.to(device))\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        iterator.set_description(f\"epoch: {epoch+1} loss:{loss.item()}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        iterator = tqdm.tqdm(test_loader)\n",
    "\n",
    "        acc = 0 \n",
    "        \n",
    "        for data, label in iterator:\n",
    "            preds = model(data.to(device))\n",
    "            \n",
    "            output = preds.data.max(1)[1]\n",
    "            corr = output.eq(label.to(device).data).sum().item()\n",
    "            acc += corr\n",
    "            \n",
    "        \n",
    "        acc = acc / len(test_data)\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        \n",
    "        if max_acc < acc:\n",
    "            max_acc = acc\n",
    "            print(\"Save Pth!\")\n",
    "            torch.save(model.state_dict(), \"ResNet.pth\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1743c7366ef20d43b658b6487c54da34f63679919181a2fe62b0bc99b4b08e22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
